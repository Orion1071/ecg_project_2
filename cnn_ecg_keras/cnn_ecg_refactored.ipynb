{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17279016880520396264\n",
      "xla_global_id: -1\n",
      "]\n",
      "Tensorflow version: 2.9.2\n",
      "Keras version: 2.9.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# Custom imports\n",
    "from physionet_processing import (fetch_h5data, spectrogram, \n",
    "                                  special_parameters, transformed_stats)\n",
    "\n",
    "from physionet_generator import DataGenerator\n",
    "\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "print('Keras version:', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folder and hdf5 dataset file\n",
    "data_root = os.path.normpath('.')\n",
    "#data_root = os.path.normpath('/media/sf_vbshare/physionet_data/')\n",
    "#data_root = os.path.normpath('/home/ubuntu/projects/csproject')\n",
    "# hd_file = os.path.join(data_root, 'physio.h5')\n",
    "hd_file = \"/Users/macbookpro/Documents/physio.h5\"\n",
    "label_file = os.path.join(data_root, 'REFERENCE-v3.csv')\n",
    "\n",
    "# Open hdf5 file\n",
    "h5file =  h5py.File(hd_file, 'r')\n",
    "\n",
    "# Get a list of dataset names \n",
    "dataset_list = list(h5file.keys())\n",
    "\n",
    "# Load the labels\n",
    "label_df = pd.read_csv(label_file, header = None, names = ['name', 'label'])\n",
    "# Filter the labels that are in the small demo set\n",
    "label_df = label_df[label_df['name'].isin(dataset_list)]\n",
    "\n",
    "# Encode labels to integer numbers\n",
    "label_set = list(sorted(label_df.label.unique()))\n",
    "encoder = LabelEncoder().fit(label_set)\n",
    "label_set_codings = encoder.transform(label_set)\n",
    "label_df = label_df.assign(encoded = encoder.transform(label_df.label))\n",
    "\n",
    "# Split the IDs in training and validation set\n",
    "test_split = 0.33\n",
    "idx = np.arange(label_df.shape[0])\n",
    "id_train, id_val, _, _ = train_test_split(idx, idx, \n",
    "                                         test_size = test_split,\n",
    "                                         shuffle = True,\n",
    "                                         random_state = 123)\n",
    "\n",
    "# Store the ids and labels in dictionaries\n",
    "partition = {'train': list(label_df.iloc[id_train,].name), \n",
    "             'validation': list(label_df.iloc[id_val,].name)}\n",
    "\n",
    "labels = dict(zip(label_df.name, label_df.encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters \n",
    "# Maximum sequence length\n",
    "max_length = 18286\n",
    "\n",
    "# Output dimensions\n",
    "sequence_length = max_length\n",
    "spectrogram_nperseg = 64 # Spectrogram window\n",
    "spectrogram_noverlap = 32 # Spectrogram overlap\n",
    "n_classes = len(label_df.label.unique())\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "def get_sample():\n",
    "    # Pick one ECG randomly from each class \n",
    "    df = pd.read_csv(label_file, header = None, names = ['name', 'label'])\n",
    "    df_set = list(df.label.unique())\n",
    "    fid_list = [np.random.choice(df[df.label == label].name.values, 1)[0] for label in df_set]\n",
    "    return fid_list\n",
    "\n",
    "name_list = get_sample()\n",
    "idx_list = [dataset_list.index(name) for name in name_list]\n",
    "\n",
    "data = fetch_h5data(h5file, idx_list, sequence_length)\n",
    "_, _, Sxx = spectrogram(data, nperseg = spectrogram_nperseg, noverlap = spectrogram_noverlap)\n",
    "dim = Sxx[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': batch_size,\n",
    "            'dim': dim,\n",
    "            'nperseg': spectrogram_nperseg,\n",
    "            'noverlap': spectrogram_noverlap,\n",
    "            'n_channels': 1,\n",
    "            'sequence_length': sequence_length,\n",
    "            'n_classes': n_classes,\n",
    "            'shuffle': True}\n",
    "\n",
    "train_generator = DataGenerator(h5file, partition['train'], labels, augment = True, **params)\n",
    "val_generator = DataGenerator(h5file, partition['validation'], labels, augment = False, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (32, 570, 33)\n",
      "y shape: (32, 4)\n",
      "X type: float64\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_generator):\n",
    "    if i == 1:\n",
    "        break\n",
    "\n",
    "X = batch[0]\n",
    "y = batch[1]\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)\n",
    "print('X type:', np.dtype(X[0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional blocks\n",
    "def conv2d_block(model, depth, layer_filters, filters_growth, \n",
    "                 strides_start, strides_end, input_shape, first_layer = False):\n",
    "    \n",
    "    ''' Convolutional block. \n",
    "    depth: number of convolutional layers in the block (4)\n",
    "    filters: 2D kernel size (32)\n",
    "    filters_growth: kernel size increase at the end of block (32)\n",
    "    first_layer: provide input_shape for first layer'''\n",
    "    \n",
    "    # Fixed parameters for convolution\n",
    "    conv_parms = {'kernel_size': (3, 3),\n",
    "                  'padding': 'same',\n",
    "                  'dilation_rate': (1, 1),\n",
    "                  'activation': None,\n",
    "                  'data_format': 'channels_last',\n",
    "                  'kernel_initializer': 'glorot_normal'}\n",
    "\n",
    "    for l in range(depth):\n",
    "\n",
    "        if first_layer:\n",
    "            \n",
    "            # First layer needs an input_shape \n",
    "            model.add(layers.Conv2D(filters = layer_filters,\n",
    "                                    strides = strides_start,\n",
    "                                    input_shape = input_shape, **conv_parms))\n",
    "            first_layer = False\n",
    "        \n",
    "        else:\n",
    "            # All other layers will not need an input_shape parameter\n",
    "            if l == depth - 1:\n",
    "                # Last layer in each block is different: adding filters and using stride 2\n",
    "                layer_filters += filters_growth\n",
    "                model.add(layers.Conv2D(filters = layer_filters,\n",
    "                                        strides = strides_end, **conv_parms))\n",
    "            else:\n",
    "                model.add(layers.Conv2D(filters = layer_filters,\n",
    "                                        strides = strides_start, **conv_parms))\n",
    "        \n",
    "        # Continue with batch normalization and activation for all layers in the block\n",
    "        model.add(layers.BatchNormalization(center = True, scale = True))\n",
    "        model.add(layers.Activation('relu'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def MeanOverTime():\n",
    "    lam_layer = layers.Lambda(lambda x: K.mean(x, axis=1), output_shape=lambda s: (1, s[2]))\n",
    "    return lam_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# Model parameters\n",
    "filters_start = 32 # Number of convolutional filters\n",
    "layer_filters = filters_start # Start with these filters\n",
    "filters_growth = 32 # Filter increase after each convBlock\n",
    "strides_start = (1, 1) # Strides at the beginning of each convBlock\n",
    "strides_end = (2, 2) # Strides at the end of each convBlock\n",
    "depth = 2 # Number of convolutional layers in each convBlock, ori 4\n",
    "n_blocks = 2 # Number of ConBlocks, ori 6\n",
    "n_channels = 1 # Number of color channgels\n",
    "input_shape = (*dim, n_channels) # input shape for first layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 570, 33, 32)       320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 570, 33, 32)      128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 570, 33, 32)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 285, 17, 64)       18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 285, 17, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 285, 17, 64)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 285, 17, 64)       36928     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 285, 17, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 285, 17, 64)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 143, 9, 96)        55392     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 143, 9, 96)       384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 143, 9, 96)        0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 143, 864)          0         \n",
      "                                                                 \n",
      " masking (Masking)           (None, 143, 864)          0         \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 864)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 3460      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,620\n",
      "Trainable params: 115,108\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "for block in range(n_blocks):\n",
    "\n",
    "    # Provide input only for the first layer\n",
    "    if block == 0:\n",
    "        provide_input = True\n",
    "    else:\n",
    "        provide_input = False\n",
    "    \n",
    "    model = conv2d_block(model, depth,\n",
    "                         layer_filters,\n",
    "                         filters_growth,\n",
    "                         strides_start, strides_end,\n",
    "                         input_shape,\n",
    "                         first_layer = provide_input)\n",
    "    \n",
    "    # Increase the number of filters after each block\n",
    "    layer_filters += filters_growth\n",
    "\n",
    "\n",
    "\n",
    "# Remove the frequency dimension, so that the output can feed into LSTM\n",
    "# Reshape to (batch, time steps, filters)\n",
    "model.add(layers.Reshape((-1, 864)))\n",
    "model.add(layers.core.Masking(mask_value = 0.0))\n",
    "model.add(MeanOverTime())\n",
    "\n",
    "# And a fully connected layer for the output\n",
    "model.add(layers.Dense(4, activation='sigmoid', kernel_regularizer = regularizers.l2(0.1)))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 22:48:11.365543: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 28s 561ms/step - loss: 1.4615 - acc: 0.5575 - val_loss: 2.2821 - val_acc: 0.5850\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 1.0803 - acc: 0.5875 - val_loss: 1.0134 - val_acc: 0.5750\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 1.0544 - acc: 0.5844 - val_loss: 1.1232 - val_acc: 0.3781\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['acc'])\n",
    "              \n",
    "h = model.fit(train_generator,\n",
    "                              steps_per_epoch = 50,\n",
    "                              epochs = 3,\n",
    "                              validation_data = val_generator,\n",
    "                              validation_steps = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "predictions:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1]\n",
      "actual:  [3, 1, 1, 2, 2, 2, 0, 1, 1, 2, 1, 2, 1, 0, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 0, 3, 1, 1, 2, 2, 3, 3, 2, 1, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 0, 2, 1, 1, 3, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 0, 2, 2, 2, 2, 0, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 0, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 3, 0, 0, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 0, 1, 0, 1, 0, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 0, 2, 3, 2, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0, 0, 1, 2, 2, 1, 2, 1, 2, 2, 1, 0, 2, 3, 1, 1, 1, 2, 1, 1, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 2, 2, 2, 1, 1, 0, 2, 1, 1, 1, 2, 0, 2, 2, 2, 3, 1, 1, 1, 1, 0, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 0, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 0, 2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 2, 1, 1, 1, 2, 0, 1, 0, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 0, 2, 0, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 0, 0, 1, 1, 3, 1, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 3, 2, 0, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 3, 0, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 0, 2, 1, 2, 1, 1, 2, 3, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 0, 0, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 0, 1, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 2, 0, 2, 1, 0, 2, 1, 1, 2, 3, 2, 3, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "actual = []\n",
    "\n",
    "for i, data in enumerate(train_generator):\n",
    "    pred = model.predict(data[0])\n",
    "    for j in range(batch_size):\n",
    "        predictions.append(pred[j].argmax())\n",
    "        actual.append(data[1][j].argmax())\n",
    "    if(i==20):\n",
    "        break\n",
    "\n",
    "print(\"predictions: \", predictions)\n",
    "print(\"actual: \",actual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('mac_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dae103b0abefff14f74f1e104d855e7141743c65472217b3d8c8917ec22807b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import pickle\n",
    "import time\n",
    "import timeit\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from physionet_processing import (fetch_h5data, spectrogram, \n",
    "                                  special_parameters, transformed_stats)\n",
    "\n",
    "from physionet_processing import (zero_filter, extend_ts, \n",
    "                                  random_resample, spectrogram, norm_float)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score\n",
    "#levinthal \n",
    "hd_file = \"/scratch/thurasx/ecg_project_2/cnn_ecg_keras/physio.h5\"\n",
    "label_file = \"/scratch/thurasx/ecg_project_2/cnn_ecg_keras/REFERENCE-v3.csv\"\n",
    "FILENAME = \"11\"\n",
    "BINARY = FALSE\n",
    "# mac \n",
    "# hd_file = \"/Users/macbookpro/Documents/physio.h5\"\n",
    "# label_file = \"/Users/macbookpro/Documents/ecg_project_2/cnn_ecg_keras/REFERENCE-v3.csv\"\n",
    "h5file =  h5py.File(hd_file, 'r')\n",
    "# Open hdf5 file\n",
    "\n",
    "\n",
    "# Get a list of dataset names \n",
    "dataset_list = list(h5file.keys())\n",
    "\n",
    "# Load the labels\n",
    "label_df = pd.read_csv(label_file, header = None, names = ['name', 'label'])\n",
    "# Filter the labels that are in the small demo set\n",
    "label_df = label_df[label_df['name'].isin(dataset_list)]\n",
    "\n",
    "\n",
    "# Encode labels to integer numbers\n",
    "label_set = list(sorted(label_df.label.unique()))\n",
    "encoder = LabelEncoder().fit(label_set)\n",
    "label_set_codings = encoder.transform(label_set)\n",
    "label_df = label_df.assign(encoded = encoder.transform(label_df.label))\n",
    "labels = dict(zip(label_df.name, label_df.encoded))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(f\"/scratch/thurasx/ecg_project_2/cnn_ecg_keras/cnn_ecg_testing/cnn_small_{FILENAME}_testlabel.pcl\", \"rb\") as f:\n",
    "    test_labels = pickle.load(f)\n",
    "\n",
    "# test_labels = list(label_df.iloc[id_train,].name) + list(label_df.iloc[id_val,].name) + list(label_df.iloc[id_test,].name)\n",
    "# print(len(test_labels))\n",
    "max_length = 18286\n",
    "\n",
    "# Output dimensions\n",
    "sequence_length = max_length\n",
    "spectrogram_nperseg = 64 # Spectrogram window\n",
    "spectrogram_noverlap = 32 # Spectrogram overlap\n",
    "n_classes = len(label_df.label.unique())\n",
    "batch_size = 32\n",
    "\n",
    "# calculate image dimensions\n",
    "data = fetch_h5data(h5file, [0], sequence_length)\n",
    "_, _, Sxx = spectrogram(data, nperseg = spectrogram_nperseg, noverlap = spectrogram_noverlap)\n",
    "dim = Sxx[0].shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size= batch_size\n",
    "dim= dim\n",
    "nperseg= spectrogram_nperseg\n",
    "noverlap= spectrogram_noverlap\n",
    "n_channels= 1\n",
    "sequence_length= sequence_length\n",
    "n_classes=n_classes\n",
    "shuffle= True\n",
    "data_mean = -9.01\n",
    "data_std = 9.00\n",
    "# Initialization\n",
    "augment = False\n",
    "batch_size = len(test_labels)\n",
    "X = np.empty((batch_size, *dim, n_channels), dtype = float)\n",
    "y = np.empty((batch_size), dtype = int)\n",
    "for i, ID in enumerate(test_labels):\n",
    "    # if i == 10:\n",
    "    #     break\n",
    "    data = extend_ts(h5file[ID]['ecgdata'][:, 0], sequence_length)\n",
    "    data = np.reshape(data, (1, len(data)))\n",
    "\n",
    "    if augment:\n",
    "    \n",
    "        # dropout bursts\n",
    "        data = zero_filter(data, threshold = 2, depth = 10)\n",
    "    \n",
    "        # random resampling\n",
    "        data = random_resample(data)\n",
    "    \n",
    "    # Generate spectrogram\n",
    "    data_spectrogram = spectrogram(data, nperseg = nperseg, noverlap = noverlap)[2]\n",
    "    \n",
    "    # Normalize\n",
    "    data_transformed = norm_float(data_spectrogram, data_mean, data_std)\n",
    "\n",
    "    X[i,] = np.expand_dims(data_transformed, axis = 3)\n",
    "    # print(X[i,].shape)\n",
    "    # Assuming that the dataset names are unique (only 1 per label)\n",
    "    y[i] = labels[ID]\n",
    "    \n",
    "if BINARY:\n",
    "    n_classes = 2\n",
    "    for i, elm in enumerate(y):\n",
    "        if elm == 0 or elm == 1 or elm == 3:\n",
    "            y[i] = 0\n",
    "        elif elm == 2:\n",
    "            y[i] = 1\n",
    "# X = X.reshape(batch_size,570,-1)\n",
    "X_test = X\n",
    "y_test = keras.utils.to_categorical(y, num_classes=n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'full'\n",
    "model = tf.keras.models.load_model(f'/scratch/thurasx/ecg_project_2/cnn_ecg_keras/cnn_ecg_keras_tflites/keras_ecg_cnn_small_{FILENAME}.tflite')\n",
    "\n",
    "y_pre = model.predict(X_test)\n",
    "y_pred = [y_pre[i].argmax()for i in y_pre]\n",
    "y_true = [y_test[i].argmax()for i in y_test]\n",
    "labels = ['Other', 'Normal', 'Atrial Fibrillation', 'Noise']\n",
    "print(\"F1 score: \", f1_score(y_true, y_pred, average='weighted'), FILENAME)\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred), \"Name: \", FILENAME)\n",
    "cm = confusion_matrix(y_true, y_pred, labels)\n",
    "cmd = ConfusionMatrixDisplay(cm)\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=f'/scratch/thurasx/ecg_project_2/cnn_ecg_keras/cnn_ecg_keras_tflites/keras_ecg_cnn_small_{FILENAME}.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "print(input_shape)\n",
    "# print(input_shape.reshape(570,33,1))\n",
    "\n",
    "# inference\n",
    "ret_results = []\n",
    "for i,data in enumerate(X_test):  \n",
    "    # print(data[i].reshape(540,33))\n",
    "    # data = data.reshape(1,540,33,1)\n",
    "    \n",
    "    X = np.empty((1, 570, 33, 1), dtype = float)\n",
    "    X[0,] = data\n",
    "    start = timeit.timeit()\n",
    "    input_data = X.astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    end = timeit.timeit()\n",
    "    ret_results.append([start, end, y_test[i].argmax(), output_data.argmax()])\n",
    "\n",
    "# print(ret_results)\n",
    "# with open(f\"/Users/macbookpro/Documents/ecg_project_2/cnn_ecg_keras/cnn_ecg_testing/small_{FILENAME}_results.pcl\", \"wb\") as f:\n",
    "#     pickle.dump(ret_results, f)\n",
    "\n",
    "\n",
    "y_pred = [i[3] for i in ret_results]\n",
    "y_true = [i[2] for i in ret_results]\n",
    "labels = ['Other', 'Normal', 'Atrial Fibrillation', 'Noise']\n",
    "print(\"F1 score: \", f1_score(y_true, y_pred, average='weighted'), FILENAME)\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred), \"Name: \", FILENAME)\n",
    "cm = confusion_matrix(y_true, y_pred, labels)\n",
    "cmd = ConfusionMatrixDisplay(cm)\n",
    "cmd.plot()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
